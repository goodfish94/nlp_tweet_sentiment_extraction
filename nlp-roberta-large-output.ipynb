{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport warnings\nimport random\nimport torch \nfrom torch import nn\nimport torch.optim as optim\nfrom sklearn.model_selection import StratifiedKFold\nimport tokenizers\nfrom transformers import RobertaModel, RobertaConfig\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Seed"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def seed_everything(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nseed = 42\nseed_everything(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class TweetDataset(torch.utils.data.Dataset):\n    def __init__(self, df, max_len=105):\n        self.df = df\n        self.max_len = max_len\n        self.labeled = 'selected_text' in df\n        self.tokenizer = tokenizers.ByteLevelBPETokenizer(\n            vocab_file='../input/robertalarge/vocab.json', \n            merges_file='../input/robertalarge/merges.txt', \n            lowercase=True,\n            add_prefix_space=True)\n\n    def __getitem__(self, index):\n        data = {}\n        row = self.df.iloc[index]\n        \n        ids, masks, tweet, offsets, sentiment, ID_ = self.get_input_data(row)\n        data['ids'] = ids              \n        data['masks'] = masks      \n        data['tweet'] = tweet      \n        data['offsets'] = offsets \n        data['sentiment'] = sentiment\n        data['ID'] = ID_\n        \n        if self.labeled:\n            start_idx, end_idx = self.get_target_idx(row, tweet, offsets)\n            data['start_idx'] = start_idx\n            data['end_idx'] = end_idx\n        \n        return data\n\n    def __len__(self):\n        return len(self.df)\n    \n    def get_input_data(self, row):\n        tweet = \" \" + \" \".join(row.text.lower().split())\n        encoding = self.tokenizer.encode(tweet)\n        sentiment_id = self.tokenizer.encode(row.sentiment).ids\n        ids = [0] + sentiment_id + [2, 2] + encoding.ids + [2]\n        offsets = [(0, 0)] * 4 + encoding.offsets + [(0, 0)]\n                \n        pad_len = self.max_len - len(ids)\n        if pad_len > 0:\n            ids += [1] * pad_len\n            offsets += [(0, 0)] * pad_len\n        \n        ids = torch.tensor(ids)\n        masks = torch.where(ids != 1, torch.tensor(1), torch.tensor(0))\n        offsets = torch.tensor(offsets)\n        \n        sentiment = row.sentiment\n        ID_ = row.textID\n        \n        return ids, masks, tweet, offsets, sentiment, ID_\n        \n    def get_target_idx(self, row, tweet, offsets):\n        selected_text = \" \" +  \" \".join(row.selected_text.lower().split())\n\n        len_st = len(selected_text) - 1\n        idx0 = None\n        idx1 = None\n\n        for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n            if \" \" + tweet[ind: ind+len_st] == selected_text:\n                idx0 = ind\n                idx1 = ind + len_st - 1\n                break\n\n        char_targets = [0] * len(tweet)\n        if idx0 != None and idx1 != None:\n            for ct in range(idx0, idx1 + 1):\n                char_targets[ct] = 1\n\n        target_idx = []\n        for j, (offset1, offset2) in enumerate(offsets):\n            if sum(char_targets[offset1: offset2]) > 0:\n                target_idx.append(j)\n\n        start_idx = target_idx[0]\n        end_idx = target_idx[-1]\n        \n        return start_idx, end_idx\n        \ndef get_train_val_loaders(df, train_idx, val_idx, batch_size=8):\n    train_df = df.iloc[train_idx]\n    val_df = df.iloc[val_idx]\n\n    train_loader = torch.utils.data.DataLoader(\n        TweetDataset(train_df), \n        batch_size=batch_size, \n        shuffle=True, \n        num_workers=2,\n        drop_last=True)\n\n    val_loader = torch.utils.data.DataLoader(\n        TweetDataset(val_df), \n        batch_size=batch_size, \n        shuffle=False, \n        num_workers=2)\n\n    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n\n    return dataloaders_dict\n\ndef get_test_loader(df, batch_size=32):\n    loader = torch.utils.data.DataLoader(\n        TweetDataset(df), \n        batch_size=batch_size, \n        shuffle=False, \n        num_workers=2)    \n    return loader","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class roberta_large_one_layer(nn.Module):\n    def __init__(self):\n        super(roberta_large_one_layer, self).__init__()\n        \n        config = RobertaConfig.from_pretrained(\n            '../input/robertalarge/config.json', output_hidden_states=True)    \n        self.roberta = RobertaModel.from_pretrained(\n            '../input/robertalarge/pytorch_model.bin', config=config)\n        self.dropout = nn.Dropout(0.5)\n        self.fc = nn.Linear(config.hidden_size*4, 2)\n#         self.rl = nn.LeakyReLU()\n#         self.fc2 = nn.Linear(2000 , 1000)\n#         self.rl2 = nn.LeakyReLU()\n#         self.fc3 = nn.Linear(1000 , 2)\n\n        \n       \n        nn.init.normal_(self.fc.weight, std=0.02)\n        nn.init.normal_(self.fc.bias, 0)\n#         nn.init.normal_(self.fc2.weight, std=0.02)\n#         nn.init.normal_(self.fc2.bias, 0)\n#         nn.init.normal_(self.fc3.weight, std=0.02)\n#         nn.init.normal_(self.fc3.bias, 0)\n#         nn.init.normal_(self.fc2.weight, std=0.02)\n      \n        \n\n    def forward(self, input_ids, attention_mask):\n        _, _, y = self.roberta(input_ids, attention_mask)\n         \n        x = torch.cat((y[-1], y[-2], y[-3], y[-4]), dim=-1)\n        x = self.dropout(x)\n        x = self.fc(x)\n#         x = self.rl(x)\n#         x = self.fc2(x)\n#         x = self.rl2(x)\n#         x = self.fc3(x)\n       \n        \n        start_logits, end_logits = x.split(1, dim=-1)\n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n                \n        return start_logits, end_logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class roberta_large_three_layer(nn.Module):\n    def __init__(self):\n        super(roberta_large_three_layer, self).__init__()\n        \n        config = RobertaConfig.from_pretrained(\n            '../input/robertalarge/config.json', output_hidden_states=True)    \n        self.roberta = RobertaModel.from_pretrained(\n            '../input/robertalarge/pytorch_model.bin', config=config)\n        self.dropout = nn.Dropout(0.5)\n        self.fc = nn.Linear(config.hidden_size * 4 , 1000)\n        self.rl = nn.LeakyReLU()\n        \n        \n        self.fc2 = nn.Linear(1000 , 2)\n\n        \n       \n        nn.init.normal_(self.fc.weight, std=0.02)\n        nn.init.normal_(self.fc.bias, 0)\n        nn.init.normal_(self.fc2.weight, std=0.02)\n      \n        \n\n    def forward(self, input_ids, attention_mask):\n        _, _, y = self.roberta(input_ids, attention_mask)\n         \n        x = y = torch.cat((y[-1], y[-2],y[-3], y[-4]), dim=-1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        x = self.rl(x)\n        x = self.fc2(x)\n       \n        \n        start_logits, end_logits = x.split(1, dim=-1)\n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n                \n        return start_logits, end_logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class robert_2_fc_model(nn.Module):\n    def __init__(self):\n        super(robert_2_fc_model, self).__init__()\n        \n        config = RobertaConfig.from_pretrained('../input/roberta-base/config.json')\n        config.output_hidden_states=True\n        \n        self.roberta = transformers.RobertaModel.from_pretrained('../input/roberta-base/pytorch_model.bin', config = config)\n        self.drop_out = nn.Dropout(0.5)\n        \n        \n        self.fc1      = nn.Linear(768 * 4, 1000)\n        self.rl1      = nn.LeakyReLU()\n        self.fc2      = nn.Linear(1000, 2)\n#         self.rl2      = nn.LeakyReLU()\n#         self.fc3      = nn.Linear(500 ,2 )\n\n        torch.nn.init.normal_(self.fc1.weight, std=0.02)\n        torch.nn.init.normal_(self.fc2.weight, std=0.02)\n#         torch.nn.init.normal_(self.fc3.weight, std=0.02)\n        \n        torch.nn.init.normal_(self.fc1.bias, 0.0)\n        torch.nn.init.normal_(self.fc2.bias, 0.0)\n#         torch.nn.init.normal_(self.fc3.bias, 0.0)\n        \n        \n    \n        \n    def forward(self,ids, token_ids, mask):\n        _, _, y = self.roberta( ids, attention_mask = mask) # get hidden state (max_len, 768)\n        # y = hidden state \n        y = torch.cat((y[-1], y[-2], y[-3],y[-4] ), dim=-1)  # output from the last two layers. Output of each layer has shape [batch size][max len][768]\n        \n        y = self.drop_out(y)\n        y = self.fc1(y)\n        y = self.rl1(y)\n        y = self.fc2(y)\n\n        \n        output = y.squeeze(-1)\n        st, en = y.split(1,dim = -1)\n        st = st.squeeze(-1) # propto prob of st \n        en = en.squeeze(-1) # propto prob of en \n        return st, en  \n        \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loss Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(start_logits, end_logits, start_positions, end_positions):\n    ce_loss = nn.CrossEntropyLoss()\n    start_loss = ce_loss(start_logits, start_positions)\n    end_loss = ce_loss(end_logits, end_positions)    \n    total_loss = start_loss + end_loss\n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_selected_text(text, start_idx, end_idx, offsets):\n    selected_text = \"\"\n    for ix in range(start_idx, end_idx + 1):\n        selected_text += text[offsets[ix][0]: offsets[ix][1]]\n        if (ix + 1) < len(offsets) and offsets[ix][1] < offsets[ix + 1][0]:\n            selected_text += \" \"\n    return selected_text\n\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\ndef compute_jaccard_score(text, start_idx, end_idx, start_logits, end_logits, offsets):\n    start_pred = np.argmax(start_logits)\n    end_pred = np.argmax(end_logits)\n    if start_pred > end_pred:\n        pred = text\n    else:\n        pred = get_selected_text(text, start_pred, end_pred, offsets)\n        \n    true = get_selected_text(text, start_idx, end_idx, offsets)\n    \n    return jaccard(true, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(model, dataloader, optimizer = None ):\n    model.cuda()\n    model.train()\n    model.eval()\n    iter_ = 0 \n    \n    sum_start_logits = []\n    sum_end_logits = [] \n    \n    for data in dataloader:\n        if( iter_ % 20 ==0):\n            print('iter',iter_ )\n        \n        ids = data['ids'].cuda()\n        masks = data['masks'].cuda()\n        ID_ = data['ID']\n        sentiment = data['sentiment']\n   \n        with torch.set_grad_enabled(False):\n            output = model(ids, masks)\n        \n            sm = nn.Softmax(dim=1)\n\n            start_logits = sm( output[0] )\n            end_logits   = sm( output[1] )\n        \n            \n            for i in range(len(ids)): \n                sum_start_logits.append( start_logits[i] )\n                sum_end_logits.append( end_logits[i] )\n                iter_ = iter_ + 1  \n                \n    return [np.asarray(sum_start_logits), np.asarray(sum_end_logits) ] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_df = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\ntest_df['text'] = test_df['text'].astype(str)\ntest_loader = get_test_loader(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel_path =  [\"../input/robertaallsentiment/model_\"+str(i) for i in range(1,6) ]\n\nsum_st_logits = 0.0\nsum_en_logits = 0.0\nfor path in model_path:\n    model = torch.load(path)\n    model.cuda()\n    model.train()\n    model.eval()\n    iter_ = 0 \n    \n    st = []\n    en = []\n    for data in test_loader:\n        if( iter_ % 20 ==0):\n            print('iter',iter_ )\n        \n        ids = data['ids'].cuda()\n        masks = data['masks'].cuda()\n        ID_ = data['ID']\n        sentiment = data['sentiment']\n   \n        with torch.set_grad_enabled(False):\n            output = model(ids, None, masks)\n        \n            sm = nn.Softmax(dim=1)\n\n            start_logits = sm( output[0] )\n            end_logits   = sm( output[1] )\n        \n            \n            for i in range(len(ids)): \n                st.append( start_logits[i].cpu().numpy() )\n                en.append( end_logits[i].cpu().numpy()  )\n                iter_ = iter_ + 1  \n                \n        \n                \n    st, en = np.asarray(st), np.asarray(en) \n\n    sum_st_logits += st\n    sum_en_logits += en \n    \nst_1 = sum_st_logits/5.0\nen_1 = sum_en_logits/5.0\n\n                \n    \n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodel_list = [ '../input/robertalargethreelayerv1/roberta_fold4.pth' ,'../input/robertalargethreelayerv1/roberta_fold5.pth',\n             '../input/robertalargethreelayerv2/roberta_fold2.pth' ,'../input/robertalargethreelayerv2/roberta_fold3.pth',\n             '../input/robertalargethreelayerv3/roberta_fold1.pth' ]\n\n\n\nsum_st_logits = 0.0\nsum_en_logits = 0.0\nmodel = roberta_large_three_layer()\n\nsum_start_logits = 0.0\nsum_end_logits = 0.0\nfor fold in range(0, 5):\n    print(\"Fold \",fold )\n    model.load_state_dict(torch.load(  model_list[fold]) )\n#     optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n    model.cuda()\n    model.train()\n    model.eval()\n    iter_ = 0 \n    \n   \n    st = []\n    en = []\n    for data in test_loader:\n        if( iter_ % 20 ==0):\n            print('iter',iter_ )\n        \n        ids = data['ids'].cuda()\n        masks = data['masks'].cuda()\n        ID_ = data['ID']\n        sentiment = data['sentiment']\n   \n        with torch.set_grad_enabled(False):\n            output = model(ids, masks)\n        \n            sm = nn.Softmax(dim=1)\n\n            start_logits = sm( output[0] )\n            end_logits   = sm( output[1] )\n        \n            \n            for i in range(len(ids)): \n                st.append( start_logits[i].cpu().numpy() )\n                en.append( end_logits[i].cpu().numpy()  )\n                iter_ = iter_ + 1  \n                \n    st, en = np.asarray(st), np.asarray(en) \n\n    sum_st_logits += st\n    sum_en_logits += en \n    \nst_2 = sum_st_logits/5.0\nen_2 = sum_en_logits/5.0\n\n                \n  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodel_list = [ '../input/robertalargeonelayerv1/roberta_fold1.pth' ,'../input/robertalargeonelayerv2/roberta_fold2.pth',\n             '../input/robertalargeonelayerv2/roberta_fold3.pth' ,'../input/robertalargeonelayerv3/roberta_fold4.pth',\n             '../input/robertalargeonelayerv3/roberta_fold5.pth' ]\n\n\n\nsum_st_logits = 0.0\nsum_en_logits = 0.0\nmodel = roberta_large_one_layer()\n\nsum_start_logits = 0.0\nsum_end_logits = 0.0\nfor fold in range(0, 5):\n    print(\"Fold \",fold )\n    model.load_state_dict(torch.load(  model_list[fold]) )\n#     optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n    model.cuda()\n    model.train()\n    model.eval()\n    iter_ = 0 \n    \n   \n    st = []\n    en = []\n    for data in test_loader:\n        if( iter_ % 20 ==0):\n            print('iter',iter_ )\n        \n        ids = data['ids'].cuda()\n        masks = data['masks'].cuda()\n        ID_ = data['ID']\n        sentiment = data['sentiment']\n   \n        with torch.set_grad_enabled(False):\n            output = model(ids, masks)\n        \n            sm = nn.Softmax(dim=1)\n\n            start_logits = sm( output[0] )\n            end_logits   = sm( output[1] )\n        \n            \n            for i in range(len(ids)): \n                st.append( start_logits[i].cpu().numpy() )\n                en.append( end_logits[i].cpu().numpy()  )\n                iter_ = iter_ + 1  \n                \n    st, en = np.asarray(st), np.asarray(en) \n\n    sum_st_logits += st\n    sum_en_logits += en \n    \nst_3 = sum_st_logits/5.0\nen_3 = sum_en_logits/5.0\n\n                \n  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = [] \nID_list = []\nit_ = 0 \nweight = [4.0,2.0,3.0]\nfor data in test_loader:\n    tweet = data['tweet']\n    offsets = data['offsets'].numpy()\n    sentiment = data['sentiment']\n    ID_ = data['ID']\n    \n    for i in range(len(tweet)):    \n        if( sentiment[i] != 'neutral'):\n            st_ = weight[0] * st_1[it_] + weight[1] * st_2[it_] + weight[2] * st_3[it_] \n            en_ = weight[0] * en_1[it_] + weight[1] * en_2[it_] + weight[2] * en_3[it_]\n        else:\n            st_ =  weight[1] * st_2[it_] + weight[2] * st_3[it_] \n            en_ =  weight[1] * en_2[it_] + weight[2] * en_3[it_]\n#         st_ = st_3[it_]\n#         en_ = en_3[it_]\n        start_pred = np.argmax(st_)\n        end_pred = np.argmax(en_)\n        if start_pred > end_pred :\n            pred = tweet[i]\n        else:\n            pred = get_selected_text(tweet[i], start_pred, end_pred, offsets[i])\n        predictions.append(pred)\n        ID_list.append(ID_[i])\n        it_ += 1\n        \nprint(len(ID_list), len(predictions))\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {'textID':ID_list, 'selected_text':predictions}\ndf = pd.DataFrame.from_dict(dic)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['selected_text'] = df['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\ndf['selected_text'] = df['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\ndf['selected_text'] = df['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\ndf.to_csv('submission.csv', index=False)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}